{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: How To Reduce Your Production Model Size by 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we illustrate using 38 real-world regression and classification problems that, thanks to the `kxy` package, you can achieve the same XGBoost performance with only 5% of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, roc_auc_score\n",
    "\n",
    "from kxy_datasets.regressions import all_regression_datasets\n",
    "from kxy_datasets.classifications import all_classification_datasets\n",
    "\n",
    "from kxy.learning import get_xgboost_learner\n",
    "from kxy.misc.predictors import NaivePredictor\n",
    "from kxy.learning.leanml_predictor import LeanMLPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic Function To Load/Train/Save A Compressed Version of Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_features_df, target_column, problem_type, learner_func, \\\n",
    "                feature_selection_method, path):\n",
    "    '''\n",
    "    Train a custom model with or without feature compression.\n",
    "    '''\n",
    "    cls = LeanMLPredictor if feature_selection_method == 'leanml' else NaivePredictor\n",
    "    try:\n",
    "        # First try to load the model from disk\n",
    "        predictor = cls.load(path, learner_func)\n",
    "    except:\n",
    "        try:\n",
    "            # Train the model from scratch if it is not found from disk\n",
    "            results = train_features_df.kxy.fit(target_column, learner_func, \\\n",
    "                problem_type=problem_type, feature_selection_method=feature_selection_method)\n",
    "        except:\n",
    "            # Some models do not like NAs\n",
    "            train_features_df = train_features_df.dropna(axis=0)\n",
    "            results = train_features_df.kxy.fit(target_column, learner_func, \\\n",
    "                problem_type=problem_type, feature_selection_method=feature_selection_method)\n",
    "        predictor = results['predictor']\n",
    "        \n",
    "        # Save the trained model to disk\n",
    "        predictor.save(path)\n",
    "    \n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions To Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./cache/', exist_ok=True)\n",
    "\n",
    "# Utility functions\n",
    "def regression_benchmark(learner_func, model_name):\n",
    "    '''\n",
    "    Run all regression experiments for a given model.\n",
    "    '''\n",
    "    try:\n",
    "        with open('./cache/%s_regression_benchmark_perfs.json' % model_name, 'r') as f:\n",
    "            perfs = json.load(f)\n",
    "    except:\n",
    "        perfs = {}\n",
    "\n",
    "    try:\n",
    "        with open('./cache/%s_regression_benchmark_n_features.json' % model_name, 'r') as f:\n",
    "            n_features = json.load(f)\n",
    "    except:\n",
    "        n_features = {}\n",
    "        \n",
    "    try:\n",
    "        with open('./cache/regression_n_rows.json', 'r') as f:\n",
    "            n_rows = json.load(f)\n",
    "    except:\n",
    "        n_rows = {}\n",
    "\n",
    "    for dataset_cls in all_regression_datasets:\n",
    "        print()\n",
    "        print('Dataset: %s' % dataset_cls.__name__)\n",
    "        dataset = dataset_cls()\n",
    "        target_column = dataset.y_column\n",
    "        dataset_name = dataset.name\n",
    "        perfs[dataset_name] = perfs.get(dataset_name, {})\n",
    "        n_features[dataset_name] = n_features.get(dataset_name, {})\n",
    "        df = dataset.df\n",
    "        n_rows[dataset_name] = df.shape[0]\n",
    "\n",
    "        # Features generation\n",
    "        features_df = df.kxy.generate_features(entity=None, max_lag=None, entity_name='*', \\\n",
    "            exclude=[target_column])\n",
    "        train_features_df, test_features_df = train_test_split(features_df, test_size=0.2, \\\n",
    "            random_state=0)\n",
    "        test_labels_df = test_features_df.loc[:, [target_column]]\n",
    "        test_features_df = test_features_df.drop(target_column, axis=1)\n",
    "        path = './cache/%s-%s-regression-benchmark.sav' % (model_name, dataset_name)\n",
    "\n",
    "        print('%s %d Features, Target: %s' % (dataset_name, train_features_df.shape[1]-1, target_column))\n",
    "        \n",
    "        # LeanML vs. No Feature Seletion\n",
    "        dataset_performance = perfs[dataset_name].copy()\n",
    "        dataset_n_features = n_features[dataset_name].copy()\n",
    "        for feature_selection_method in ['leanml', 'none']:\n",
    "            # Training\n",
    "            predictor = train_model(train_features_df, target_column, 'regression', learner_func, \\\n",
    "                feature_selection_method, path)                    \n",
    "            n_selected_features = len(predictor.selected_variables)\n",
    "\n",
    "            # Evaluation\n",
    "            try:\n",
    "                try:\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                except:\n",
    "                    nan_features = test_features_df.isna().any(axis=1)\n",
    "                    test_features_df = test_features_df.loc[np.logical_not(nan_features), :]\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                    test_labels_df = test_labels_df.loc[np.logical_not(nan_features), :]\n",
    "\n",
    "                perf = r2_score(\\\n",
    "                    test_labels_df[target_column].values, \\\n",
    "                    test_predictions_df[target_column].values)\n",
    "                perf = max(perf, 0.0)\n",
    "            except:\n",
    "                logging.exception('Somthing bad happened')\n",
    "                perf = 0.0\n",
    "                \n",
    "            print('%s, Feature Selection Method: %s --- R-Squared: %.2f, Number of Selected Features: %d' % (\\\n",
    "                dataset_name, feature_selection_method, perf, n_selected_features))\n",
    "            \n",
    "            dataset_performance[feature_selection_method]=float(perf)\n",
    "            dataset_n_features[feature_selection_method]=int(n_selected_features)\n",
    "            \n",
    "        perfs[dataset_name]=dataset_performance.copy()\n",
    "        with open('./cache/%s_regression_benchmark_perfs.json' % model_name, 'w') as f:\n",
    "            json.dump(perfs, f)\n",
    "\n",
    "        n_features[dataset_name]=dataset_n_features.copy()\n",
    "        with open('./cache/%s_regression_benchmark_n_features.json' % model_name, 'w') as f:\n",
    "            json.dump(n_features, f)\n",
    "\n",
    "        with open('./cache/regression_n_rows.json', 'w') as f:\n",
    "            json.dump(n_rows, f)\n",
    "\n",
    "\n",
    "def classification_benchmark(learner_func, model_name):\n",
    "    '''\n",
    "    Run all classification experiments for a given model.\n",
    "    '''\n",
    "    try:\n",
    "        with open('./cache/%s_classification_benchmark_perfs.json' % model_name, 'r') as f:\n",
    "            perfs = json.load(f)\n",
    "    except:\n",
    "        perfs = {}\n",
    "\n",
    "    try:\n",
    "        with open('./cache/%s_classification_benchmark_n_features.json' % model_name, 'r') as f:\n",
    "            n_features = json.load(f)\n",
    "    except:\n",
    "        n_features = {}\n",
    "        \n",
    "    try:\n",
    "        with open('./cache/classification_n_rows.json', 'r') as f:\n",
    "            n_rows = json.load(f)\n",
    "    except:\n",
    "        n_rows = {}\n",
    "\n",
    "    # LeanML\n",
    "    for dataset_cls in all_classification_datasets:\n",
    "        print()\n",
    "        print('Dataset: %s' % dataset_cls.__name__)\n",
    "        dataset = dataset_cls()\n",
    "        target_column = dataset.y_column\n",
    "        dataset_name = dataset.name\n",
    "        perfs[dataset_name] = perfs.get(dataset_name, {})\n",
    "        n_features[dataset_name] = n_features.get(dataset_name, {})\n",
    "        df = dataset.df\n",
    "        n_rows[dataset_name] = df.shape[0]\n",
    "\n",
    "        # Features generation\n",
    "        features_df = df.kxy.generate_features(entity=None, max_lag=None, entity_name='*', \\\n",
    "            exclude=[target_column])\n",
    "\n",
    "        if target_column in features_df:\n",
    "            target_df = pd.get_dummies(df[target_column], prefix=str(target_column))\n",
    "            features_df = features_df.drop(target_column, axis=1)\n",
    "            features_df = pd.concat([features_df, target_df], axis=1)\n",
    "\n",
    "        train_features_df, test_features_df = train_test_split(features_df, test_size=0.2, \\\n",
    "            random_state=0)\n",
    "        target_columns = [_ for _ in features_df.columns if str(_).startswith(str(target_column))]\n",
    "        target_column = target_columns[0]\n",
    "        test_labels_df = test_features_df.loc[:, [target_column]]\n",
    "        train_labels_df = train_features_df.loc[:, [target_column]]\n",
    "\n",
    "        for col in target_columns:\n",
    "            if col != target_column:\n",
    "                test_features_df = test_features_df.drop(col, axis=1)\n",
    "                train_features_df = train_features_df.drop(col, axis=1)\n",
    "            else:\n",
    "                test_features_df = test_features_df.drop(col, axis=1)\n",
    "\n",
    "        path = './cache/%s-%s-classification-benchmark.sav' % (model_name, dataset_name)\n",
    "        print('%s %d Features, Target: %s' % (dataset_name, train_features_df.shape[1]-1, target_column))\n",
    "\n",
    "        # LeanML vs. No Feature Seletion\n",
    "        dataset_performance = perfs[dataset_name].copy()\n",
    "        dataset_n_features = n_features[dataset_name].copy()\n",
    "        for feature_selection_method in ['leanml', 'none']:\n",
    "            # Training\n",
    "            predictor = train_model(train_features_df, target_column, 'classification', learner_func, \\\n",
    "                feature_selection_method, path)                \n",
    "            n_selected_features = len(predictor.selected_variables)\n",
    "\n",
    "            # Evaluation\n",
    "            try:\n",
    "                try:\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                except:\n",
    "                    nan_features = test_features_df.isna().any(axis=1)\n",
    "                    test_features_df = test_features_df.loc[np.logical_not(nan_features), :]\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                    test_labels_df = test_labels_df.loc[np.logical_not(nan_features), :]\n",
    "                perf = roc_auc_score(\\\n",
    "                    test_labels_df[target_column].values, \\\n",
    "                    test_predictions_df[target_column].values, \\\n",
    "                    multi_class='ovr')\n",
    "                perf = max(perf, 0.0)\n",
    "            except:\n",
    "                logging.exception('Somthing bad happened')\n",
    "                perf = 0.5\n",
    "                \n",
    "            dataset_performance[feature_selection_method]=float(perf)\n",
    "            dataset_n_features[feature_selection_method]=int(n_selected_features)\n",
    "\n",
    "            print('%s, Feature Selection Method: %s --- AUC: %.2f, Number of Features Selected: %d' % (\\\n",
    "                dataset_name, feature_selection_method, perf, n_selected_features))\n",
    "            \n",
    "        perfs[dataset_name]=dataset_performance.copy()\n",
    "        with open('./cache/%s_classification_benchmark_perfs.json' % model_name, 'w') as f:\n",
    "            json.dump(perfs, f)\n",
    "\n",
    "        n_features[dataset_name]=dataset_n_features.copy()\n",
    "        with open('./cache/%s_classification_benchmark_n_features.json' % model_name, 'w') as f:\n",
    "            json.dump(n_features, f)\n",
    "\n",
    "        with open('./cache/classification_n_rows.json', 'w') as f:\n",
    "            json.dump(n_rows, f)\n",
    "            \n",
    "            \n",
    "        \n",
    "def summarize_results():\n",
    "    '''\n",
    "    Print a dataframe summarizing all datasets used.\n",
    "    '''\n",
    "    print()\n",
    "    model_name = 'xgboost'\n",
    "    dataset_names = []\n",
    "    sources = []\n",
    "    ds = []\n",
    "    leanml_ds = []\n",
    "    ns = []\n",
    "    problem_types = []\n",
    "    full_ps = []\n",
    "    comp_ps = []\n",
    "\n",
    "    problem_type = None\n",
    "    for l in [all_classification_datasets, all_regression_datasets]:\n",
    "        problem_type = 'classification' if problem_type is None else 'regression'\n",
    "        try:\n",
    "            with open('./cache/%s_%s_benchmark_n_features.json' % (model_name, problem_type), 'r') as f:\n",
    "                n_features = json.load(f)\n",
    "            with open('./cache/%s_%s_benchmark_perfs.json' % (model_name, problem_type), 'r') as f:\n",
    "                perfs = json.load(f)\n",
    "            with open('./cache/%s_n_rows.json' % problem_type, 'r') as f:\n",
    "                n_rows = json.load(f)\n",
    "\n",
    "        except:\n",
    "            logging.exception('Something bad happened')\n",
    "            n_features = {}\n",
    "            n_rows = {}\n",
    "\n",
    "        sub_dataset_names = [_ for _ in n_rows.keys()]\n",
    "        for dataset_name in sub_dataset_names:\n",
    "            dataset_names += [dataset_name.replace('UCI', '').replace('Kaggle', '')]\n",
    "            ns += [n_rows[dataset_name]]\n",
    "            ds += [n_features[dataset_name]['none']] \n",
    "            leanml_ds += [n_features[dataset_name]['leanml']] \n",
    "            full_ps += [perfs[dataset_name]['none']] \n",
    "            comp_ps += [perfs[dataset_name]['leanml']] \n",
    "            sources += ['UCI' if 'UCI' in dataset_name else 'Kaggle']\n",
    "            problem_types += [problem_type]\n",
    "\n",
    "    df = pd.DataFrame(data={'Dataset': dataset_names, 'Number of Rows': ns, 'Number of Candidate Features': ds, \\\n",
    "                            'Number of Features Selected': leanml_ds, 'Performance (Full Model)': full_ps, \\\n",
    "                            'Performance (Compressed Model)': comp_ps, 'Problem Type': problem_types})\n",
    "    df = df.sort_values(by=['Number of Candidate Features', 'Number of Rows', 'Problem Type'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print('Avg. Performance Full Model: %.2f' % np.mean(df['Performance (Full Model)'])) \n",
    "    print('Avg. Performance Compressed Model: %.2f' % np.mean(df['Performance (Compressed Model)']))\n",
    "    print('Avg. Compression Rate: %d%s' % (int(np.round(100.*(1.-np.mean(1.*\\\n",
    "                    df['Number of Features Selected']/df['Number of Candidate Features'])))), '%'))\n",
    "    print('Weighted Avg. Compression Rate: %d%s' % (int(np.round(100.*(1.-np.sum(1.*\\\n",
    "                    df['Number of Features Selected']/np.sum(df['Number of Candidate Features']))))), '%'))\n",
    "    pd.set_option('display.float_format','{:.2f}'.format)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_regression_benchmark():\n",
    "    '''\n",
    "    Run all regression experiments for XGBoost.\n",
    "    '''\n",
    "    regressor_cls = get_xgboost_learner('xgboost.XGBRegressor')\n",
    "    regression_benchmark(regressor_cls, 'xgboost')\n",
    "\n",
    "\n",
    "def xgboost_classification_benchmark():\n",
    "    '''\n",
    "    Run all classification experiments for XGBoost.\n",
    "    '''\n",
    "    classifier_cls = get_xgboost_learner('xgboost.XGBClassifier')\n",
    "    classification_benchmark(classifier_cls, 'xgboost')\n",
    "    \n",
    "    \n",
    "def run_experiments():\n",
    "    '''\n",
    "    Run all experiments.\n",
    "    '''\n",
    "    print()\n",
    "    print('======================')\n",
    "    print('    Model: XGBoost    ')\n",
    "    print('======================')\n",
    "    print()\n",
    "    print('Regression Datasets')\n",
    "    xgboost_regression_benchmark()\n",
    "\n",
    "    print()\n",
    "    print('Classification Datasets')\n",
    "    xgboost_classification_benchmark()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "    Model: XGBoost    \n",
      "======================\n",
      "\n",
      "Regression Datasets\n",
      "\n",
      "Dataset: Abalone\n",
      "UCIAbalone 38 Features, Target: Age\n",
      "UCIAbalone, Feature Selection Method: leanml --- R-Squared: 0.53, Number of Selected Features: 8\n",
      "UCIAbalone, Feature Selection Method: none --- R-Squared: 0.52, Number of Selected Features: 38\n",
      "\n",
      "Dataset: AirFoil\n",
      "UCIAirFoil 25 Features, Target: Sound Pressure\n",
      "UCIAirFoil, Feature Selection Method: leanml --- R-Squared: 0.92, Number of Selected Features: 9\n",
      "UCIAirFoil, Feature Selection Method: none --- R-Squared: 0.93, Number of Selected Features: 25\n",
      "\n",
      "Dataset: AirQuality\n",
      "UCIAirQuality 70 Features, Target: C6H6(GT)\n",
      "UCIAirQuality, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 2\n",
      "UCIAirQuality, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 70\n",
      "\n",
      "Dataset: BikeSharing\n",
      "UCIBikeSharing 90 Features, Target: cnt\n",
      "UCIBikeSharing, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 4\n",
      "UCIBikeSharing, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 90\n",
      "\n",
      "Dataset: BlogFeedback\n",
      "UCIBlogFeedback 1400 Features, Target: y\n",
      "UCIBlogFeedback, Feature Selection Method: leanml --- R-Squared: 0.57, Number of Selected Features: 13\n",
      "UCIBlogFeedback, Feature Selection Method: none --- R-Squared: 0.58, Number of Selected Features: 1400\n",
      "\n",
      "Dataset: CTSlices\n",
      "UCICTSlices 1925 Features, Target: reference\n",
      "UCICTSlices, Feature Selection Method: leanml --- R-Squared: 0.98, Number of Selected Features: 34\n",
      "UCICTSlices, Feature Selection Method: none --- R-Squared: 0.99, Number of Selected Features: 1925\n",
      "\n",
      "Dataset: Concrete\n",
      "UCIConcrete 40 Features, Target: Concrete Compressive Strength\n",
      "UCIConcrete, Feature Selection Method: leanml --- R-Squared: 0.92, Number of Selected Features: 11\n",
      "UCIConcrete, Feature Selection Method: none --- R-Squared: 0.93, Number of Selected Features: 40\n",
      "\n",
      "Dataset: EnergyEfficiency\n",
      "UCIEnergyEfficiency 45 Features, Target: Y1\n",
      "UCIEnergyEfficiency, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 11\n",
      "UCIEnergyEfficiency, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 45\n",
      "\n",
      "Dataset: FacebookComments\n",
      "UCIFacebookComments 265 Features, Target: y\n",
      "UCIFacebookComments, Feature Selection Method: leanml --- R-Squared: 0.58, Number of Selected Features: 13\n",
      "UCIFacebookComments, Feature Selection Method: none --- R-Squared: 0.72, Number of Selected Features: 265\n",
      "\n",
      "Dataset: NavalPropulsion\n",
      "UCINavalPropulsion 85 Features, Target: GT Compressor Decay\n",
      "UCINavalPropulsion, Feature Selection Method: leanml --- R-Squared: 0.99, Number of Selected Features: 5\n",
      "UCINavalPropulsion, Feature Selection Method: none --- R-Squared: 0.99, Number of Selected Features: 85\n",
      "\n",
      "Dataset: OnlineNews\n",
      "UCIOnlineNews 290 Features, Target:  shares\n",
      "UCIOnlineNews, Feature Selection Method: leanml --- R-Squared: 0.00, Number of Selected Features: 26\n",
      "UCIOnlineNews, Feature Selection Method: none --- R-Squared: 0.00, Number of Selected Features: 290\n",
      "\n",
      "Dataset: Parkinson\n",
      "UCIParkinson 105 Features, Target: motor_UPDRS\n",
      "UCIParkinson, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 2\n",
      "UCIParkinson, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 105\n",
      "\n",
      "Dataset: PowerPlant\n",
      "UCIPowerPlant 20 Features, Target: PE\n",
      "UCIPowerPlant, Feature Selection Method: leanml --- R-Squared: 0.97, Number of Selected Features: 8\n",
      "UCIPowerPlant, Feature Selection Method: none --- R-Squared: 0.97, Number of Selected Features: 20\n",
      "\n",
      "Dataset: RealEstate\n",
      "UCIRealEstate 30 Features, Target: Y house price of unit area\n",
      "UCIRealEstate, Feature Selection Method: leanml --- R-Squared: 0.72, Number of Selected Features: 9\n",
      "UCIRealEstate, Feature Selection Method: none --- R-Squared: 0.72, Number of Selected Features: 30\n",
      "\n",
      "Dataset: SocialMediaBuzz\n",
      "UCISocialMediaBuzz 385 Features, Target: annotation\n",
      "UCISocialMediaBuzz, Feature Selection Method: leanml --- R-Squared: 0.94, Number of Selected Features: 6\n",
      "UCISocialMediaBuzz, Feature Selection Method: none --- R-Squared: 0.95, Number of Selected Features: 385\n",
      "\n",
      "Dataset: Superconductivity\n",
      "UCISuperconductivity 405 Features, Target: critical_temp\n",
      "UCISuperconductivity, Feature Selection Method: leanml --- R-Squared: 0.90, Number of Selected Features: 17\n",
      "UCISuperconductivity, Feature Selection Method: none --- R-Squared: 0.91, Number of Selected Features: 405\n",
      "\n",
      "Dataset: WhiteWineQuality\n",
      "UCIWhiteWineQuality 55 Features, Target: quality\n",
      "UCIWhiteWineQuality, Feature Selection Method: leanml --- R-Squared: 0.37, Number of Selected Features: 29\n",
      "UCIWhiteWineQuality, Feature Selection Method: none --- R-Squared: 0.44, Number of Selected Features: 55\n",
      "\n",
      "Dataset: YachtHydrodynamics\n",
      "UCIYachtHydrodynamics 30 Features, Target: Residuary Resistance\n",
      "UCIYachtHydrodynamics, Feature Selection Method: leanml --- R-Squared: 0.99, Number of Selected Features: 1\n",
      "UCIYachtHydrodynamics, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 30\n",
      "\n",
      "Dataset: YearPredictionMSD\n",
      "UCIYearPredictionMSD 450 Features, Target: y\n",
      "UCIYearPredictionMSD, Feature Selection Method: leanml --- R-Squared: 0.31, Number of Selected Features: 36\n",
      "UCIYearPredictionMSD, Feature Selection Method: none --- R-Squared: 0.32, Number of Selected Features: 450\n",
      "\n",
      "Dataset: HousePricesAdvanced\n",
      "KaggleHousePricesAdvanced 432 Features, Target: SalePrice\n",
      "KaggleHousePricesAdvanced, Feature Selection Method: leanml --- R-Squared: 0.88, Number of Selected Features: 8\n",
      "KaggleHousePricesAdvanced, Feature Selection Method: none --- R-Squared: 0.83, Number of Selected Features: 432\n",
      "\n",
      "Classification Datasets\n",
      "\n",
      "Dataset: APSFailure\n",
      "UCIAPSFailure 850 Features, Target: class_neg\n",
      "UCIAPSFailure, Feature Selection Method: leanml --- AUC: 0.73, Number of Features Selected: 9\n",
      "UCIAPSFailure, Feature Selection Method: none --- AUC: 0.91, Number of Features Selected: 850\n",
      "\n",
      "Dataset: Adult\n",
      "UCIAdult 202 Features, Target: Income_ <=50K\n",
      "UCIAdult, Feature Selection Method: leanml --- AUC: 0.78, Number of Features Selected: 19\n",
      "UCIAdult, Feature Selection Method: none --- AUC: 0.79, Number of Features Selected: 202\n",
      "\n",
      "Dataset: Avila\n",
      "UCIAvila 50 Features, Target: Class_A\n",
      "UCIAvila, Feature Selection Method: leanml --- AUC: 1.00, Number of Features Selected: 30\n",
      "UCIAvila, Feature Selection Method: none --- AUC: 1.00, Number of Features Selected: 50\n",
      "\n",
      "Dataset: BankMarketing\n",
      "UCIBankMarketing 103 Features, Target: y_no\n",
      "UCIBankMarketing, Feature Selection Method: leanml --- AUC: 0.76, Number of Features Selected: 14\n",
      "UCIBankMarketing, Feature Selection Method: none --- AUC: 0.77, Number of Features Selected: 103\n",
      "\n",
      "Dataset: BankNote\n",
      "UCIBankNote 20 Features, Target: Is Fake_0\n",
      "UCIBankNote, Feature Selection Method: leanml --- AUC: 0.99, Number of Features Selected: 4\n",
      "UCIBankNote, Feature Selection Method: none --- AUC: 1.00, Number of Features Selected: 20\n",
      "\n",
      "Dataset: CardDefault\n",
      "UCICardDefault 115 Features, Target: default payment next month_0\n",
      "UCICardDefault, Feature Selection Method: leanml --- AUC: 0.66, Number of Features Selected: 26\n",
      "UCICardDefault, Feature Selection Method: none --- AUC: 0.66, Number of Features Selected: 115\n",
      "\n",
      "Dataset: DiabeticRetinopathy\n",
      "UCIDiabeticRetinopathy 95 Features, Target: y_0\n",
      "UCIDiabeticRetinopathy, Feature Selection Method: leanml --- AUC: 0.70, Number of Features Selected: 34\n",
      "UCIDiabeticRetinopathy, Feature Selection Method: none --- AUC: 0.65, Number of Features Selected: 95\n",
      "\n",
      "Dataset: EEGEyeState\n",
      "UCIEEGEyeState 70 Features, Target: y_0\n",
      "UCIEEGEyeState, Feature Selection Method: leanml --- AUC: 0.92, Number of Features Selected: 17\n",
      "UCIEEGEyeState, Feature Selection Method: none --- AUC: 0.91, Number of Features Selected: 70\n",
      "\n",
      "Dataset: Landsat\n",
      "UCILandsat 180 Features, Target: 36_1\n",
      "UCILandsat, Feature Selection Method: leanml --- AUC: 0.98, Number of Features Selected: 5\n",
      "UCILandsat, Feature Selection Method: none --- AUC: 0.98, Number of Features Selected: 180\n",
      "\n",
      "Dataset: LetterRecognition\n",
      "UCILetterRecognition 80 Features, Target: 0_A\n",
      "UCILetterRecognition, Feature Selection Method: leanml --- AUC: 0.98, Number of Features Selected: 22\n",
      "UCILetterRecognition, Feature Selection Method: none --- AUC: 0.98, Number of Features Selected: 80\n",
      "\n",
      "Dataset: MagicGamma\n",
      "UCIMagicGamma 50 Features, Target: 10_g\n",
      "UCIMagicGamma, Feature Selection Method: leanml --- AUC: 0.86, Number of Features Selected: 15\n",
      "UCIMagicGamma, Feature Selection Method: none --- AUC: 0.86, Number of Features Selected: 50\n",
      "\n",
      "Dataset: SensorLessDrive\n",
      "UCISensorLessDrive 240 Features, Target: 48_1.0\n",
      "UCISensorLessDrive, Feature Selection Method: leanml --- AUC: 1.00, Number of Features Selected: 23\n",
      "UCISensorLessDrive, Feature Selection Method: none --- AUC: 1.00, Number of Features Selected: 240\n",
      "\n",
      "Dataset: Shuttle\n",
      "UCIShuttle 45 Features, Target: 9_1\n",
      "UCIShuttle, Feature Selection Method: leanml --- AUC: 1.00, Number of Features Selected: 3\n",
      "UCIShuttle, Feature Selection Method: none --- AUC: 1.00, Number of Features Selected: 45\n",
      "\n",
      "Dataset: SkinSegmentation\n",
      "UCISkinSegmentation 15 Features, Target: y_1\n",
      "UCISkinSegmentation, Feature Selection Method: leanml --- AUC: 1.00, Number of Features Selected: 7\n",
      "UCISkinSegmentation, Feature Selection Method: none --- AUC: 1.00, Number of Features Selected: 15\n",
      "\n",
      "Dataset: HeartAttack\n",
      "KaggleHeartAttack 65 Features, Target: output_0\n",
      "KaggleHeartAttack, Feature Selection Method: leanml --- AUC: 0.84, Number of Features Selected: 9\n",
      "KaggleHeartAttack, Feature Selection Method: none --- AUC: 0.86, Number of Features Selected: 65\n",
      "\n",
      "Dataset: HeartDisease\n",
      "KaggleHeartDisease 65 Features, Target: target_0\n",
      "KaggleHeartDisease, Feature Selection Method: leanml --- AUC: 0.84, Number of Features Selected: 9\n",
      "KaggleHeartDisease, Feature Selection Method: none --- AUC: 0.86, Number of Features Selected: 65\n",
      "\n",
      "Dataset: Titanic\n",
      "KaggleTitanic 1754 Features, Target: Survived_0\n",
      "KaggleTitanic, Feature Selection Method: leanml --- AUC: 0.81, Number of Features Selected: 26\n",
      "KaggleTitanic, Feature Selection Method: none --- AUC: 0.82, Number of Features Selected: 1754\n",
      "\n",
      "Dataset: WaterQuality\n",
      "KaggleWaterQuality 45 Features, Target: Potability_0\n",
      "KaggleWaterQuality, Feature Selection Method: leanml --- AUC: 0.59, Number of Features Selected: 31\n",
      "KaggleWaterQuality, Feature Selection Method: none --- AUC: 0.60, Number of Features Selected: 45\n"
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg. Performance Full Model: 0.83\n",
      "Avg. Performance Compressed Model: 0.82\n",
      "Avg. Compression Rate: 82%\n",
      "Weighted Avg. Compression Rate: 95%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Number of Rows</th>\n",
       "      <th>Number of Candidate Features</th>\n",
       "      <th>Number of Features Selected</th>\n",
       "      <th>Performance (Full Model)</th>\n",
       "      <th>Performance (Compressed Model)</th>\n",
       "      <th>Problem Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SkinSegmentation</td>\n",
       "      <td>245057</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BankNote</td>\n",
       "      <td>1372</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PowerPlant</td>\n",
       "      <td>9568</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AirFoil</td>\n",
       "      <td>1503</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YachtHydrodynamics</td>\n",
       "      <td>308</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RealEstate</td>\n",
       "      <td>414</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>4177</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Concrete</td>\n",
       "      <td>1030</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EnergyEfficiency</td>\n",
       "      <td>768</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WaterQuality</td>\n",
       "      <td>3276</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shuttle</td>\n",
       "      <td>58000</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MagicGamma</td>\n",
       "      <td>19020</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Avila</td>\n",
       "      <td>20867</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WhiteWineQuality</td>\n",
       "      <td>4898</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HeartAttack</td>\n",
       "      <td>303</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HeartDisease</td>\n",
       "      <td>303</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AirQuality</td>\n",
       "      <td>8991</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EEGEyeState</td>\n",
       "      <td>14980</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LetterRecognition</td>\n",
       "      <td>20000</td>\n",
       "      <td>80</td>\n",
       "      <td>22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NavalPropulsion</td>\n",
       "      <td>11934</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BikeSharing</td>\n",
       "      <td>17379</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DiabeticRetinopathy</td>\n",
       "      <td>1151</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BankMarketing</td>\n",
       "      <td>41188</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Parkinson</td>\n",
       "      <td>5875</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CardDefault</td>\n",
       "      <td>30000</td>\n",
       "      <td>115</td>\n",
       "      <td>26</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Landsat</td>\n",
       "      <td>6435</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Adult</td>\n",
       "      <td>48843</td>\n",
       "      <td>202</td>\n",
       "      <td>19</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SensorLessDrive</td>\n",
       "      <td>58509</td>\n",
       "      <td>240</td>\n",
       "      <td>23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FacebookComments</td>\n",
       "      <td>209074</td>\n",
       "      <td>265</td>\n",
       "      <td>13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OnlineNews</td>\n",
       "      <td>39644</td>\n",
       "      <td>290</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SocialMediaBuzz</td>\n",
       "      <td>583250</td>\n",
       "      <td>385</td>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Superconductivity</td>\n",
       "      <td>21263</td>\n",
       "      <td>405</td>\n",
       "      <td>17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HousePricesAdvanced</td>\n",
       "      <td>1460</td>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>YearPredictionMSD</td>\n",
       "      <td>515345</td>\n",
       "      <td>450</td>\n",
       "      <td>36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>APSFailure</td>\n",
       "      <td>76000</td>\n",
       "      <td>850</td>\n",
       "      <td>9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BlogFeedback</td>\n",
       "      <td>60021</td>\n",
       "      <td>1400</td>\n",
       "      <td>13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>891</td>\n",
       "      <td>1754</td>\n",
       "      <td>26</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CTSlices</td>\n",
       "      <td>53500</td>\n",
       "      <td>1925</td>\n",
       "      <td>34</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset  Number of Rows  Number of Candidate Features  \\\n",
       "0      SkinSegmentation          245057                            15   \n",
       "1              BankNote            1372                            20   \n",
       "2            PowerPlant            9568                            20   \n",
       "3               AirFoil            1503                            25   \n",
       "4    YachtHydrodynamics             308                            30   \n",
       "5            RealEstate             414                            30   \n",
       "6               Abalone            4177                            38   \n",
       "7              Concrete            1030                            40   \n",
       "8      EnergyEfficiency             768                            45   \n",
       "9          WaterQuality            3276                            45   \n",
       "10              Shuttle           58000                            45   \n",
       "11           MagicGamma           19020                            50   \n",
       "12                Avila           20867                            50   \n",
       "13     WhiteWineQuality            4898                            55   \n",
       "14          HeartAttack             303                            65   \n",
       "15         HeartDisease             303                            65   \n",
       "16           AirQuality            8991                            70   \n",
       "17          EEGEyeState           14980                            70   \n",
       "18    LetterRecognition           20000                            80   \n",
       "19      NavalPropulsion           11934                            85   \n",
       "20          BikeSharing           17379                            90   \n",
       "21  DiabeticRetinopathy            1151                            95   \n",
       "22        BankMarketing           41188                           103   \n",
       "23            Parkinson            5875                           105   \n",
       "24          CardDefault           30000                           115   \n",
       "25              Landsat            6435                           180   \n",
       "26                Adult           48843                           202   \n",
       "27      SensorLessDrive           58509                           240   \n",
       "28     FacebookComments          209074                           265   \n",
       "29           OnlineNews           39644                           290   \n",
       "30      SocialMediaBuzz          583250                           385   \n",
       "31    Superconductivity           21263                           405   \n",
       "32  HousePricesAdvanced            1460                           432   \n",
       "33    YearPredictionMSD          515345                           450   \n",
       "34           APSFailure           76000                           850   \n",
       "35         BlogFeedback           60021                          1400   \n",
       "36              Titanic             891                          1754   \n",
       "37             CTSlices           53500                          1925   \n",
       "\n",
       "    Number of Features Selected  Performance (Full Model)  \\\n",
       "0                             7                      1.00   \n",
       "1                             4                      1.00   \n",
       "2                             8                      0.97   \n",
       "3                             9                      0.93   \n",
       "4                             1                      1.00   \n",
       "5                             9                      0.72   \n",
       "6                             8                      0.52   \n",
       "7                            11                      0.93   \n",
       "8                            11                      1.00   \n",
       "9                            31                      0.60   \n",
       "10                            3                      1.00   \n",
       "11                           15                      0.86   \n",
       "12                           30                      1.00   \n",
       "13                           29                      0.44   \n",
       "14                            9                      0.86   \n",
       "15                            9                      0.86   \n",
       "16                            2                      1.00   \n",
       "17                           17                      0.91   \n",
       "18                           22                      0.98   \n",
       "19                            5                      0.99   \n",
       "20                            4                      1.00   \n",
       "21                           34                      0.65   \n",
       "22                           14                      0.77   \n",
       "23                            2                      1.00   \n",
       "24                           26                      0.66   \n",
       "25                            5                      0.98   \n",
       "26                           19                      0.79   \n",
       "27                           23                      1.00   \n",
       "28                           13                      0.72   \n",
       "29                           26                      0.00   \n",
       "30                            6                      0.95   \n",
       "31                           17                      0.91   \n",
       "32                            8                      0.83   \n",
       "33                           36                      0.32   \n",
       "34                            9                      0.91   \n",
       "35                           13                      0.58   \n",
       "36                           26                      0.82   \n",
       "37                           34                      0.99   \n",
       "\n",
       "    Performance (Compressed Model)    Problem Type  \n",
       "0                             1.00  classification  \n",
       "1                             0.99  classification  \n",
       "2                             0.97      regression  \n",
       "3                             0.92      regression  \n",
       "4                             0.99      regression  \n",
       "5                             0.72      regression  \n",
       "6                             0.53      regression  \n",
       "7                             0.92      regression  \n",
       "8                             1.00      regression  \n",
       "9                             0.59  classification  \n",
       "10                            1.00  classification  \n",
       "11                            0.86  classification  \n",
       "12                            1.00  classification  \n",
       "13                            0.37      regression  \n",
       "14                            0.84  classification  \n",
       "15                            0.84  classification  \n",
       "16                            1.00      regression  \n",
       "17                            0.92  classification  \n",
       "18                            0.98  classification  \n",
       "19                            0.99      regression  \n",
       "20                            1.00      regression  \n",
       "21                            0.70  classification  \n",
       "22                            0.76  classification  \n",
       "23                            1.00      regression  \n",
       "24                            0.66  classification  \n",
       "25                            0.98  classification  \n",
       "26                            0.78  classification  \n",
       "27                            1.00  classification  \n",
       "28                            0.58      regression  \n",
       "29                            0.00      regression  \n",
       "30                            0.94      regression  \n",
       "31                            0.90      regression  \n",
       "32                            0.88      regression  \n",
       "33                            0.31      regression  \n",
       "34                            0.73  classification  \n",
       "35                            0.57      regression  \n",
       "36                            0.81  classification  \n",
       "37                            0.98      regression  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = summarize_results()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Features: 555, Number of Candidate Features: 10229\n"
     ]
    }
   ],
   "source": [
    "print('Number of Selected Features: %d, Number of Candidate Features: %d' % \n",
    "      (results_df['Number of Features Selected'].sum(), results_df['Number of Candidate Features'].sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kxy",
   "language": "python",
   "name": "kxy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
