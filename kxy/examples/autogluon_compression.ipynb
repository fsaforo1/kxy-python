{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon: How To Get The Same Performance With Only 5% of Your Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we illustrate using 38 real-world regression and classification problems that the `kxy` package can achieve the same AutoGluon performance with only 5% of features on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, roc_auc_score\n",
    "\n",
    "from kxy_datasets.regressions import all_regression_datasets\n",
    "from kxy_datasets.classifications import all_classification_datasets\n",
    "\n",
    "from kxy.learning import get_autogluon_learner\n",
    "from kxy.misc.predictors import NaivePredictor\n",
    "from kxy.learning.leanml_predictor import LeanMLPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic Function To Load/Train/Save A Compressed Version of Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_features_df, target_column, problem_type, learner_func, \\\n",
    "                feature_selection_method, path):\n",
    "    '''\n",
    "    Train a custom model with or without feature compression.\n",
    "    '''\n",
    "    cls = LeanMLPredictor if feature_selection_method == 'leanml' else NaivePredictor\n",
    "    try:\n",
    "        # First try to load the model from disk\n",
    "        predictor = cls.load(path, learner_func)\n",
    "    except:\n",
    "        try:\n",
    "            # Train the model from scratch if it is not found from disk\n",
    "            results = train_features_df.kxy.fit(target_column, learner_func, \\\n",
    "                problem_type=problem_type, feature_selection_method=feature_selection_method, \\\n",
    "                path=path)\n",
    "        except:\n",
    "            # Some models do not like NAs\n",
    "            train_features_df = train_features_df.dropna(axis=0)\n",
    "            results = train_features_df.kxy.fit(target_column, learner_func, \\\n",
    "                problem_type=problem_type, feature_selection_method=feature_selection_method, \\\n",
    "                path=path)\n",
    "        predictor = results['predictor']\n",
    "        \n",
    "        # Save the trained model to disk\n",
    "        predictor.save(path)\n",
    "    \n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions To Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./cache/', exist_ok=True)\n",
    "\n",
    "# Utility functions\n",
    "def regression_benchmark(learner_func, model_name):\n",
    "    '''\n",
    "    Run all regression experiments for a given model.\n",
    "    '''\n",
    "    try:\n",
    "        with open('./cache/%s_regression_benchmark_perfs.json' % model_name, 'r') as f:\n",
    "            perfs = json.load(f)\n",
    "    except:\n",
    "        perfs = {}\n",
    "\n",
    "    try:\n",
    "        with open('./cache/%s_regression_benchmark_n_features.json' % model_name, 'r') as f:\n",
    "            n_features = json.load(f)\n",
    "    except:\n",
    "        n_features = {}\n",
    "        \n",
    "    try:\n",
    "        with open('./cache/regression_n_rows.json', 'r') as f:\n",
    "            n_rows = json.load(f)\n",
    "    except:\n",
    "        n_rows = {}\n",
    "\n",
    "    for dataset_cls in all_regression_datasets:\n",
    "        print()\n",
    "        print('Dataset: %s' % dataset_cls.__name__)\n",
    "        dataset = dataset_cls()\n",
    "        target_column = dataset.y_column\n",
    "        dataset_name = dataset.name\n",
    "        perfs[dataset_name] = perfs.get(dataset_name, {})\n",
    "        n_features[dataset_name] = n_features.get(dataset_name, {})\n",
    "        df = dataset.df\n",
    "        n_rows[dataset_name] = df.shape[0]\n",
    "\n",
    "        # Features generation\n",
    "        features_df = df.kxy.generate_features(entity=None, max_lag=None, entity_name='*', \\\n",
    "            exclude=[target_column])\n",
    "        train_features_df, test_features_df = train_test_split(features_df, test_size=0.2, \\\n",
    "            random_state=0)\n",
    "        test_labels_df = test_features_df.loc[:, [target_column]]\n",
    "        test_features_df = test_features_df.drop(target_column, axis=1)\n",
    "        \n",
    "        print('%s %d Features, Target: %s' % (dataset_name, train_features_df.shape[1]-1, target_column))\n",
    "        \n",
    "        # LeanML vs. No Feature Seletion\n",
    "        dataset_performance = perfs[dataset_name].copy()\n",
    "        dataset_n_features = n_features[dataset_name].copy()\n",
    "        path = './cache/%s-%s-regression-benchmark.sav' % (model_name, dataset_name)\n",
    "        \n",
    "        for feature_selection_method in ['leanml', 'none']:\n",
    "            # Training\n",
    "            predictor = train_model(train_features_df, target_column, 'regression', learner_func, \\\n",
    "                feature_selection_method, path)                    \n",
    "            n_selected_features = len(predictor.selected_variables)\n",
    "\n",
    "            # Evaluation\n",
    "            try:\n",
    "                try:\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                except:\n",
    "                    nan_features = test_features_df.isna().any(axis=1)\n",
    "                    test_features_df = test_features_df.loc[np.logical_not(nan_features), :]\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                    test_labels_df = test_labels_df.loc[np.logical_not(nan_features), :]\n",
    "\n",
    "                perf = r2_score(\\\n",
    "                    test_labels_df[target_column].values, \\\n",
    "                    test_predictions_df[target_column].values)\n",
    "            except:\n",
    "                logging.exception('Somthing bad happened')\n",
    "                perf = 0.0\n",
    "                \n",
    "            print('%s, Feature Selection Method: %s --- R-Squared: %.2f, Number of Selected Features: %d' % (\\\n",
    "                dataset_name, feature_selection_method, perf, n_selected_features))\n",
    "            \n",
    "            dataset_performance[feature_selection_method]=float(perf)\n",
    "            dataset_n_features[feature_selection_method]=int(n_selected_features)\n",
    "            \n",
    "        perfs[dataset_name]=dataset_performance.copy()\n",
    "        with open('./cache/%s_regression_benchmark_perfs.json' % model_name, 'w') as f:\n",
    "            json.dump(perfs, f)\n",
    "\n",
    "        n_features[dataset_name]=dataset_n_features.copy()\n",
    "        with open('./cache/%s_regression_benchmark_n_features.json' % model_name, 'w') as f:\n",
    "            json.dump(n_features, f)\n",
    "\n",
    "        with open('./cache/regression_n_rows.json', 'w') as f:\n",
    "            json.dump(n_rows, f)\n",
    "\n",
    "\n",
    "def classification_benchmark(learner_func, model_name):\n",
    "    '''\n",
    "    Run all classification experiments for a given model.\n",
    "    '''\n",
    "    try:\n",
    "        with open('./cache/%s_classification_benchmark_perfs.json' % model_name, 'r') as f:\n",
    "            perfs = json.load(f)\n",
    "    except:\n",
    "        perfs = {}\n",
    "\n",
    "    try:\n",
    "        with open('./cache/%s_classification_benchmark_n_features.json' % model_name, 'r') as f:\n",
    "            n_features = json.load(f)\n",
    "    except:\n",
    "        n_features = {}\n",
    "        \n",
    "    try:\n",
    "        with open('./cache/classification_n_rows.json', 'r') as f:\n",
    "            n_rows = json.load(f)\n",
    "    except:\n",
    "        n_rows = {}\n",
    "\n",
    "    # LeanML\n",
    "    for dataset_cls in all_classification_datasets:\n",
    "        print()\n",
    "        print('Dataset: %s' % dataset_cls.__name__)\n",
    "        dataset = dataset_cls()\n",
    "        target_column = dataset.y_column\n",
    "        dataset_name = dataset.name\n",
    "        perfs[dataset_name] = perfs.get(dataset_name, {})\n",
    "        n_features[dataset_name] = n_features.get(dataset_name, {})\n",
    "        df = dataset.df\n",
    "        n_rows[dataset_name] = df.shape[0]\n",
    "\n",
    "        # Features generation\n",
    "        features_df = df.kxy.generate_features(entity=None, max_lag=None, entity_name='*', \\\n",
    "            exclude=[target_column])\n",
    "\n",
    "        if target_column in features_df:\n",
    "            target_df = pd.get_dummies(df[target_column], prefix=str(target_column))\n",
    "            features_df = features_df.drop(target_column, axis=1)\n",
    "            features_df = pd.concat([features_df, target_df], axis=1)\n",
    "\n",
    "        train_features_df, test_features_df = train_test_split(features_df, test_size=0.2, \\\n",
    "            random_state=0)\n",
    "        target_columns = [_ for _ in features_df.columns if str(_).startswith(str(target_column))]\n",
    "        target_column = target_columns[0]\n",
    "        test_labels_df = test_features_df.loc[:, [target_column]]\n",
    "        train_labels_df = train_features_df.loc[:, [target_column]]\n",
    "\n",
    "        for col in target_columns:\n",
    "            if col != target_column:\n",
    "                test_features_df = test_features_df.drop(col, axis=1)\n",
    "                train_features_df = train_features_df.drop(col, axis=1)\n",
    "            else:\n",
    "                test_features_df = test_features_df.drop(col, axis=1)\n",
    "\n",
    "        \n",
    "        print('%s %d Features, Target: %s' % (dataset_name, train_features_df.shape[1]-1, target_column))\n",
    "\n",
    "        # LeanML vs. No Feature Seletion\n",
    "        dataset_performance = perfs[dataset_name].copy()\n",
    "        dataset_n_features = n_features[dataset_name].copy()\n",
    "        path = './cache/%s-%s-classification-benchmark.sav' % (model_name, dataset_name)\n",
    "\n",
    "        for feature_selection_method in ['leanml', 'none']:\n",
    "            # Training\n",
    "            predictor = train_model(train_features_df, target_column, 'classification', learner_func, \\\n",
    "                feature_selection_method, path)                \n",
    "            n_selected_features = len(predictor.selected_variables)\n",
    "\n",
    "            # Evaluation\n",
    "            try:\n",
    "                try:\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                except:\n",
    "                    nan_features = test_features_df.isna().any(axis=1)\n",
    "                    test_features_df = test_features_df.loc[np.logical_not(nan_features), :]\n",
    "                    test_predictions_df = predictor.predict(test_features_df)\n",
    "                    test_labels_df = test_labels_df.loc[np.logical_not(nan_features), :]\n",
    "                perf = roc_auc_score(\\\n",
    "                    test_labels_df[target_column].values, \\\n",
    "                    test_predictions_df[target_column].values, \\\n",
    "                    multi_class='ovr')\n",
    "            except:\n",
    "                logging.exception('Somthing bad happened')\n",
    "                perf = 0.5\n",
    "                \n",
    "            dataset_performance[feature_selection_method]=float(perf)\n",
    "            dataset_n_features[feature_selection_method]=int(n_selected_features)\n",
    "\n",
    "            print('%s, Feature Selection Method: %s --- AUC: %.2f, Number of Selected Features: %d' % (\\\n",
    "                dataset_name, feature_selection_method, perf, n_selected_features))\n",
    "            \n",
    "        perfs[dataset_name]=dataset_performance.copy()\n",
    "        with open('./cache/%s_classification_benchmark_perfs.json' % model_name, 'w') as f:\n",
    "            json.dump(perfs, f)\n",
    "\n",
    "        n_features[dataset_name]=dataset_n_features.copy()\n",
    "        with open('./cache/%s_classification_benchmark_n_features.json' % model_name, 'w') as f:\n",
    "            json.dump(n_features, f)\n",
    "\n",
    "        with open('./cache/classification_n_rows.json', 'w') as f:\n",
    "            json.dump(n_rows, f)\n",
    "            \n",
    "            \n",
    "        \n",
    "def summarize_results():\n",
    "    '''\n",
    "    Print a dataframe summarizing all datasets used.\n",
    "    '''\n",
    "    print()\n",
    "    model_name = 'autogluon'\n",
    "    dataset_names = []\n",
    "    sources = []\n",
    "    ds = []\n",
    "    leanml_ds = []\n",
    "    ns = []\n",
    "    problem_types = []\n",
    "    full_ps = []\n",
    "    comp_ps = []\n",
    "\n",
    "    problem_type = None\n",
    "    for l in [all_classification_datasets, all_regression_datasets]:\n",
    "        problem_type = 'classification' if problem_type is None else 'regression'\n",
    "        try:\n",
    "            with open('./cache/%s_%s_benchmark_n_features.json' % (model_name, problem_type), 'r') as f:\n",
    "                n_features = json.load(f)\n",
    "            with open('./cache/%s_%s_benchmark_perfs.json' % (model_name, problem_type), 'r') as f:\n",
    "                perfs = json.load(f)\n",
    "            with open('./cache/%s_n_rows.json' % problem_type, 'r') as f:\n",
    "                n_rows = json.load(f)\n",
    "\n",
    "        except:\n",
    "            logging.exception('Something bad happened')\n",
    "            n_features = {}\n",
    "            n_rows = {}\n",
    "\n",
    "        sub_dataset_names = [_ for _ in n_rows.keys()]\n",
    "        for dataset_name in sub_dataset_names:\n",
    "            dataset_names += [dataset_name.replace('UCI', '').replace('Kaggle', '')]\n",
    "            ns += [n_rows[dataset_name]]\n",
    "            ds += [n_features[dataset_name]['none']] \n",
    "            leanml_ds += [n_features[dataset_name]['leanml']] \n",
    "            full_ps += [perfs[dataset_name]['none']] \n",
    "            comp_ps += [perfs[dataset_name]['leanml']] \n",
    "            sources += ['UCI' if 'UCI' in dataset_name else 'Kaggle']\n",
    "            problem_types += [problem_type]\n",
    "\n",
    "    df = pd.DataFrame(data={'Dataset': dataset_names, 'Number of Rows': ns, 'Number of Candidate Features': ds, \\\n",
    "                            'Number of Selected Features': leanml_ds, 'Performance Full Model': full_ps, \\\n",
    "                            'Performance Compressed Model': comp_ps, 'Problem Type': problem_types, \\\n",
    "                            'Source': sources})\n",
    "    df = df.sort_values(by=['Number of Candidate Features', 'Number of Rows', 'Problem Type'])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print('Avg. Performance Full Model: %.2f' % np.mean(df['Performance Full Model'])) \n",
    "    print('Avg. Performance Compressed Model: %.2f' % np.mean(df['Performance Compressed Model']))\n",
    "    print('Avg. Compression Rate: %d%s' % (int(100.*(1.-np.mean(1.*df['Number of Selected Features']/\\\n",
    "                                                     df['Number of Candidate Features']))), '%'))\n",
    "    print('Weighted Avg. Compression Rate: %d%s' % (int(100.*(1.-np.sum(1.*df['Number of Selected Features']/\\\n",
    "                                                     np.sum(df['Number of Candidate Features'])))), '%'))\n",
    "    pd.set_option('display.float_format','{:.2f}'.format)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autogluon_regression_benchmark():\n",
    "    '''\n",
    "    Run all regression experiments for AWS' AutoGluon.\n",
    "    '''\n",
    "    regressor_cls = get_autogluon_learner(problem_type='regression', verbosity=0)\n",
    "    regression_benchmark(regressor_cls, 'autogluon')\n",
    "\n",
    "\n",
    "def autogluon_classification_benchmark():\n",
    "    '''\n",
    "    Run all classification experiments for AWS' AutoGluon.\n",
    "    '''\n",
    "    classifier_cls = get_autogluon_learner(problem_type='binary', verbosity=0)\n",
    "    classification_benchmark(classifier_cls, 'autogluon')\n",
    "    \n",
    "    \n",
    "def run_experiments():\n",
    "    '''\n",
    "    Run all experiments.\n",
    "    '''\n",
    "    print()\n",
    "    print('========================')\n",
    "    print('    Model: AutoGluon    ')\n",
    "    print('========================')\n",
    "    print()\n",
    "    print('Regression Datasets')\n",
    "    autogluon_regression_benchmark()\n",
    "\n",
    "    print()\n",
    "    print('Classification Datasets')\n",
    "    autogluon_classification_benchmark()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "    Model: AutoGluon    \n",
      "========================\n",
      "\n",
      "Regression Datasets\n",
      "\n",
      "Dataset: Abalone\n",
      "UCIAbalone 38 Features, Target: Age\n",
      "UCIAbalone, Feature Selection Method: leanml --- R-Squared: 0.58, Number of Selected Features: 5\n",
      "UCIAbalone, Feature Selection Method: none --- R-Squared: 0.58, Number of Selected Features: 38\n",
      "\n",
      "Dataset: AirFoil\n",
      "UCIAirFoil 25 Features, Target: Sound Pressure\n",
      "UCIAirFoil, Feature Selection Method: leanml --- R-Squared: 0.94, Number of Selected Features: 14\n",
      "UCIAirFoil, Feature Selection Method: none --- R-Squared: 0.95, Number of Selected Features: 25\n",
      "\n",
      "Dataset: AirQuality\n",
      "UCIAirQuality 70 Features, Target: C6H6(GT)\n",
      "UCIAirQuality, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 2\n",
      "UCIAirQuality, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 70\n",
      "\n",
      "Dataset: BikeSharing\n",
      "UCIBikeSharing 90 Features, Target: cnt\n",
      "UCIBikeSharing, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 3\n",
      "UCIBikeSharing, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 90\n",
      "\n",
      "Dataset: BlogFeedback\n",
      "UCIBlogFeedback 1400 Features, Target: y\n",
      "UCIBlogFeedback, Feature Selection Method: leanml --- R-Squared: 0.59, Number of Selected Features: 17\n",
      "UCIBlogFeedback, Feature Selection Method: none --- R-Squared: 0.60, Number of Selected Features: 1400\n",
      "\n",
      "Dataset: CTSlices\n",
      "UCICTSlices 1925 Features, Target: reference\n",
      "UCICTSlices, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 31\n",
      "UCICTSlices, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 1925\n",
      "\n",
      "Dataset: Concrete\n",
      "UCIConcrete 40 Features, Target: Concrete Compressive Strength\n",
      "UCIConcrete, Feature Selection Method: leanml --- R-Squared: 0.92, Number of Selected Features: 11\n",
      "UCIConcrete, Feature Selection Method: none --- R-Squared: 0.93, Number of Selected Features: 40\n",
      "\n",
      "Dataset: EnergyEfficiency\n",
      "UCIEnergyEfficiency 45 Features, Target: Y1\n",
      "UCIEnergyEfficiency, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 7\n",
      "UCIEnergyEfficiency, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 45\n",
      "\n",
      "Dataset: FacebookComments\n",
      "UCIFacebookComments 265 Features, Target: y\n",
      "UCIFacebookComments, Feature Selection Method: leanml --- R-Squared: 0.61, Number of Selected Features: 13\n",
      "UCIFacebookComments, Feature Selection Method: none --- R-Squared: -13.36, Number of Selected Features: 265\n",
      "\n",
      "Dataset: NavalPropulsion\n",
      "UCINavalPropulsion 85 Features, Target: GT Compressor Decay\n",
      "UCINavalPropulsion, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 6\n",
      "UCINavalPropulsion, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 85\n",
      "\n",
      "Dataset: OnlineNews\n",
      "UCIOnlineNews 290 Features, Target:  shares\n",
      "UCIOnlineNews, Feature Selection Method: leanml --- R-Squared: 0.04, Number of Selected Features: 26\n",
      "UCIOnlineNews, Feature Selection Method: none --- R-Squared: -0.71, Number of Selected Features: 290\n",
      "\n",
      "Dataset: Parkinson\n",
      "UCIParkinson 105 Features, Target: motor_UPDRS\n",
      "UCIParkinson, Feature Selection Method: leanml --- R-Squared: 1.00, Number of Selected Features: 2\n",
      "UCIParkinson, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 105\n",
      "\n",
      "Dataset: PowerPlant\n",
      "UCIPowerPlant 20 Features, Target: PE\n",
      "UCIPowerPlant, Feature Selection Method: leanml --- R-Squared: 0.97, Number of Selected Features: 6\n",
      "UCIPowerPlant, Feature Selection Method: none --- R-Squared: 0.97, Number of Selected Features: 20\n",
      "\n",
      "Dataset: RealEstate\n",
      "UCIRealEstate 30 Features, Target: Y house price of unit area\n",
      "UCIRealEstate, Feature Selection Method: leanml --- R-Squared: 0.76, Number of Selected Features: 9\n",
      "UCIRealEstate, Feature Selection Method: none --- R-Squared: 0.75, Number of Selected Features: 30\n",
      "\n",
      "Dataset: SocialMediaBuzz\n",
      "UCISocialMediaBuzz 385 Features, Target: annotation\n",
      "UCISocialMediaBuzz, Feature Selection Method: leanml --- R-Squared: 0.93, Number of Selected Features: 6\n",
      "UCISocialMediaBuzz, Feature Selection Method: none --- R-Squared: 0.94, Number of Selected Features: 385\n",
      "\n",
      "Dataset: Superconductivity\n",
      "UCISuperconductivity 405 Features, Target: critical_temp\n",
      "UCISuperconductivity, Feature Selection Method: leanml --- R-Squared: 0.91, Number of Selected Features: 19\n",
      "UCISuperconductivity, Feature Selection Method: none --- R-Squared: 0.92, Number of Selected Features: 405\n",
      "\n",
      "Dataset: WhiteWineQuality\n",
      "UCIWhiteWineQuality 55 Features, Target: quality\n",
      "UCIWhiteWineQuality, Feature Selection Method: leanml --- R-Squared: 0.44, Number of Selected Features: 27\n",
      "UCIWhiteWineQuality, Feature Selection Method: none --- R-Squared: 0.48, Number of Selected Features: 55\n",
      "\n",
      "Dataset: YachtHydrodynamics\n",
      "UCIYachtHydrodynamics 30 Features, Target: Residuary Resistance\n",
      "UCIYachtHydrodynamics, Feature Selection Method: leanml --- R-Squared: 0.99, Number of Selected Features: 1\n",
      "UCIYachtHydrodynamics, Feature Selection Method: none --- R-Squared: 1.00, Number of Selected Features: 30\n",
      "\n",
      "Dataset: YearPredictionMSD\n",
      "UCIYearPredictionMSD 450 Features, Target: y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c11d874cbbd4b09a69f3529c4fca997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a367987f65654534bd9d57049bbc38b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summarize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Selected Features: %d, Number of Candidate Features: %d' % \n",
    "      (results_df['Number of Features Selected'].sum(), results_df['Number of Candidate Features'].sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kxy",
   "language": "python",
   "name": "kxy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
